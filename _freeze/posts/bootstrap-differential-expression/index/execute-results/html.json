{
  "hash": "e35a47e1d3026b4735442581a57d1873",
  "result": {
    "markdown": "---\ntitle: \"Bootstrapping Differential Expression\"\ndescription: \"How many can I do?\"\nauthor: \"Gennaro Calendo\"\ndate: \"9/22/2023\"\ncategories: [R, bioinformatics]\n---\n\n\n## Das Boot\n\nI have been playing around with the idea of bootstrapping differential \nexpression analyses, inspired by [this](https://hbiostat.org/blog/post/badb/) \nexcellent blog post from Professor Frank Harrell on how to do bad biomarker \nresearch. In the section titled, \"Difficulties of picking 'winners'\" he writes:\n\n>Efronâ€™s bootstrap can be used to fully account for the difficulty of the biomarker selection task. Selection of winners involves computing some statistic for each candidate marker, and sorting features by these strength-of-association measures. The statistic can be a crude unadjusted measure (correlation coefficient or unadjusted odds ratio, for example), or an adjusted measure. For each of a few hundred samples with replacement from the original raw dataset, one repeats the entire analysis afresh for each re-sample. All the biomarker candidates are ranked by the chosen statistic, and bootstrap percentile confidence intervals for these ranks are computed over all re-samples. 0.95 confidence limits for the rank of each candidate marker capture the stability of the ranks.\n\nSince I do a lot of analyses that involve differential expression testing where\nsamples are done in triplcate, I was curious if I could apply this resampling\nstrategy to my work to get a better idea of how often my winners are really \nwinners given we often have such small groups of samples. \n\nThis blog post is not about performing this bootstrapping workflow (I'll save\nthat for later). Rather, I want to explore how many unique bootstrap resamples\nwe expect to generate given triplicate samples and how often we should expect \nany given pattern to by sampled.\n\n## How many possible unique combinations of the data are there?\n\nSince a typical experiment consists of samples done in triplicate the question \nthen becomes, how many unique ways of bootstrapping samples are there? The \nreason I care about *unique* resamples is because when estimating differential\nexpression we are comparing the mean expression between two groups and therefore\na resample consisting of [control1, control1, control2] will give the same \nmean as resampling [control2, control1, control1].\n\nSince I'm no good at math, to examine this question I'll generate a grid of \nall possibilities and count up the unique combinations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\n\n# Create all combinations of the three samples\nsamples <- c(\"A\", \"B\", \"C\")\ndt <- setDT(expand.grid(samples, samples, samples))\n\n# Combine into a single string representing the selected samples\ndt[, sample := paste0(Var1, Var2, Var3)]\n\n# Count up the number of letters represented in each string\ndt[, `:=`(N_A = stringr::str_count(sample, \"A\"),\n          N_B = stringr::str_count(sample, \"B\"),\n          N_C = stringr::str_count(sample, \"C\"))]\n\n# Count up the unique counts -- total number of rows gives the unique ways of\n#  generating bootstraps for triplicates\n(nrow(unique(dt[, .(N_A, N_B, N_C)])))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n\nAs it turns out, this [question](https://stats.stackexchange.com/a/557626) \nhas been asked and answered already and the theoretical answer is given by $2n-1\\choose{n}$. So ${2(3)-1\\choose{3}}={5\\choose3}=10$\n\nJust to be sure, let's try again with 4 letters and check against the theoretical\nanswer\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples2 <- c(\"A\", \"B\", \"C\", \"D\")\ndt2 <- setDT(expand.grid(samples2, samples2, samples2, samples2))\ndt2[, sample := paste0(Var1, Var2, Var3, Var4)]\ndt2[, `:=`(N_A = stringr::str_count(sample, \"A\"),\n           N_B = stringr::str_count(sample, \"B\"),\n           N_C = stringr::str_count(sample, \"C\"),\n           N_D = stringr::str_count(sample, \"D\"))]\n(nrow(unique(dt2[, .(N_A, N_B, N_C, N_D)])))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 35\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchoose(2*4-1, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 35\n```\n:::\n:::\n\n\nSo if I want to generate bootstrap resamples for a 3x3 experiment there should be\n10 x 10 = 100 unique comparisons that I can make. But how often should we expect \nto see any given pattern in a set of triplicates if we perform a bunch of\nbootstraps?\n\n## Pattern counts\n\nWhat is the expected proportion of each pattern in the triplicate experiment if\nwe are to resample with replacement? We can find this by taking the proportions\nof each unique pattern from above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a string from all of the unique ways to count samples\ndt[, patterns := paste0(N_A, N_B, N_C)]\n\n# Find the proportion of each of the possible ways to combine samples\nsort(table(dt$patterns) / sum(table(dt$patterns)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n       003        030        300        012        021        102        120 \n0.03703704 0.03703704 0.03703704 0.11111111 0.11111111 0.11111111 0.11111111 \n       201        210        111 \n0.11111111 0.11111111 0.22222222 \n```\n:::\n:::\n\n\nWe can see that some patterns are more likely than others. For example, we are \njust as likely to select 0 As, 0 Bs, and 3 Cs as we are 3 As, 0 Bs, and 0 Cs. \nThis is interesting because it suggests that ~22% of our resamples should \ncontain the original samples, ~66% should contain one duplicated sample and \n~11% should contain triplicates of single sample.\n\nWe should see this if we generate samples and count the occurrences.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1011001)\n\nbootSamples <- function() {\n  # Generate the random string of selected samples\n  s <- paste(sample(c(\"A\", \"B\", \"C\"), replace = TRUE), collapse=\"\")\n  \n  # Count the number of times any individual occurs in the string\n  data.table(\n    N_A = stringr::str_count(s, \"A\"),\n    N_B = stringr::str_count(s, \"B\"),\n    N_C = stringr::str_count(s, \"C\")\n    )\n}\n\n# Generate 100 bootstrap resamples\nbootstraps <- replicate(1e2, bootSamples(), simplify = FALSE)\nbootstraps <- rbindlist(bootstraps)\nbootstraps[, patterns := paste0(N_A, N_B, N_C)]\n\n# Count the frequency of the observed patterns\nsort(table(bootstraps$patterns) / sum(table(bootstraps$patterns)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n 300  030  003  021  210  120  012  102  201  111 \n0.02 0.04 0.05 0.09 0.09 0.10 0.11 0.13 0.17 0.20 \n```\n:::\n:::\n\n\nGenerating 100 samples gets us close to the theoretical values and on average will converge on the theoretical values.\n\n## Thoughts\n\nThis is pretty interesting since it suggests that about 5% of the time (0.22 *\n0.22 = 0.048) when resampling two groups of triplicate samples I should expect to get back the same results as in the original analysis.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}